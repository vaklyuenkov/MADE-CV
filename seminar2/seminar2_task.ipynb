{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def one_hot_encoded(y, num_class):\n",
    "    n = y.shape[0]\n",
    "    onehot = np.zeros((n, num_class), dtype=\"int32\")\n",
    "    for i in range(n):\n",
    "        idx = y[i]\n",
    "        onehot[i][idx] = 1\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)  # both are not one hot encoded\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    max_x = np.max(x, axis=1, keepdims=True)\n",
    "    exp_x = np.exp(x - max_x)\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        \n",
    "# l2 regularization\n",
    "def l2_reg(layers, lam=0.001):\n",
    "    reg_loss = 0.0\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'W'):\n",
    "            reg_loss += 0.5 * lam * np.sum(layer.W * layer.W)\n",
    "    return reg_loss\n",
    "\n",
    "\n",
    "# l2 regularization grad\n",
    "def delta_l2_reg(layers, grads, lam=0.001):\n",
    "    for layer, grad in zip(layers, reversed(grads)):\n",
    "        if hasattr(layer, 'W'):\n",
    "            grad[0] += lam * layer.W\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003057, 0.24472847, 0.66524096]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.array([[1,2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=False, h=0.00001):\n",
    "    \"\"\"Evaluates gradient df/dx via finite differences:\n",
    "    df/dx ~ (f(x+h) - f(x-h)) / 2h\n",
    "    Adopted from https://github.com/ddtm/dl-course/\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print (ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        self.X = X\n",
    "        return np.maximum(X, 0)\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        self.gradInput = dout.copy()\n",
    "        self.gradInput[self.X <= 0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = ReLU()\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 12))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "\n",
    "        # Xavier init\n",
    "        self.W = np.random.randn(in_size, out_size) / np.sqrt(in_size + out_size/ 2.)\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        self.X = X\n",
    "        return X.dot(self.W) + self.b\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        self.gradW = self.X.T.dot(dout)        \n",
    "        self.gradInput = dout.dot(self.W.T)\n",
    "        self.gradB = dout.sum(axis=0)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]\n",
      " [-0.03683751  0.22613802  0.71336409  0.18683848  0.38311137  0.47141595\n",
      "  -1.06829164 -0.2807766   0.3800087   0.12426938 -0.17073428 -0.24281456]]\n"
     ]
    }
   ],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = Linear(12, 5)\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 5))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(object):\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0] # self.m == X.shape[0], y.shape == (X.shape[0], )\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y])\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        dx = self.p.copy()\n",
    "        dx[range(self.m), y] -= 1\n",
    "        dx /= self.m\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    def __init__(self, loss_func=CrossEntropyLoss(), mode = 'train'):\n",
    "    \n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.loss_func = loss_func\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "\n",
    "    def add_layer(self,layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X, self.mode)\n",
    "        return X\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            dout, grad = layer.backward(dout, self.mode)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "\n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        dout = self.loss_func.backward(out,y)\n",
    "        loss += l2_reg(self.layers)\n",
    "        grads = self.backward(dout)\n",
    "        grads = delta_l2_reg(self.layers, grads)\n",
    "        return loss, grads\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(softmax(X), axis=1)\n",
    "\n",
    "\n",
    "    def dispGradParam():\n",
    "        print(self.grads)\n",
    "    \n",
    "\n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD with momentum\n",
    "def update(velocity, params, grads, learning_rate=0.001, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]\n",
    "\n",
    "\n",
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, ...]\n",
    "        y_batch = y[i:i + minibatch_size, ...]\n",
    "\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "    return minibatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9,\n",
    "                 verbose=True, X_val=None, y_val=None, nesterov=True):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    c = 0 \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Epoch {0}\".format(i + 1))\n",
    "\n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in tqdm(minibatches):\n",
    "\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads,\n",
    "                            learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in tqdm(minibatches_val):\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "\n",
    "\n",
    "        # accuracy of model at end of epoch after all mini batch updates   \n",
    "\n",
    "        if verbose:\n",
    "            m_train = X_train.shape[0]\n",
    "            m_val = X_val.shape[0]\n",
    "            y_train_pred = np.array([], dtype=\"int64\")\n",
    "            y_val_pred = np.array([], dtype=\"int64\")\n",
    "\n",
    "            for i in range(0, m_train, minibatch_size):\n",
    "                X_tr = X_train[i:i + minibatch_size, : ]\n",
    "                y_tr = y_train[i:i + minibatch_size, ]\n",
    "                y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "            for i in range(0, m_val, minibatch_size):\n",
    "                X_va = X_val[i:i + minibatch_size, : ]\n",
    "                y_va = y_val[i:i + minibatch_size, ]\n",
    "                y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "\n",
    "            train_acc = check_accuracy(y_train, y_train_pred)\n",
    "            val_acc = check_accuracy(y_val, y_val_pred)\n",
    "\n",
    "            mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "            mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "\n",
    "\n",
    "            # early stopping with patience = 5 on val loss\n",
    "\n",
    "            if len(val_loss_epoch) == 0:\n",
    "                val_loss_epoch.append(mean_val_loss)\n",
    "            else:\n",
    "                for j in val_loss_epoch[-5:]:\n",
    "                    if mean_val_loss > j:\n",
    "                        c += 1\n",
    "                    else:\n",
    "                        c = 0\n",
    "                if c > 5:\n",
    "                    print('Early stopping')\n",
    "                    return net\n",
    "                else:\n",
    "                    c = 0\n",
    "                    val_loss_epoch.append(mean_val_loss)    \n",
    "\n",
    "\n",
    "            print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(\n",
    "                mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1022.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 787.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 313.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 799.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1207.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 847.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1286.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 645.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 919.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 305.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 832.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 725.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1260.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1171.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 503.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1218.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 552.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1053.32it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4, 4)\n",
      "Epoch 1\n",
      "Loss = 0.687618483991582 | Training Accuracy = 0.5 | Val Loss = 0.6779384633133831 | Val Accuracy = 0.5\n",
      "Epoch 2\n",
      "Loss = 0.6779384633133831 | Training Accuracy = 0.5 | Val Loss = 0.6716663975688475 | Val Accuracy = 0.5\n",
      "Epoch 3\n",
      "Loss = 0.6716663975688475 | Training Accuracy = 0.5 | Val Loss = 0.6656490505156851 | Val Accuracy = 0.5\n",
      "Epoch 4\n",
      "Loss = 0.6656490505156851 | Training Accuracy = 0.5 | Val Loss = 0.6596978843054356 | Val Accuracy = 0.5\n",
      "Epoch 5\n",
      "Loss = 0.6596978843054356 | Training Accuracy = 0.5 | Val Loss = 0.6538589733858822 | Val Accuracy = 0.5\n",
      "Epoch 6\n",
      "Loss = 0.6538589733858822 | Training Accuracy = 0.5 | Val Loss = 0.6479875839773586 | Val Accuracy = 0.5\n",
      "Epoch 7\n",
      "Loss = 0.6479875839773586 | Training Accuracy = 0.5 | Val Loss = 0.6421428874880504 | Val Accuracy = 0.5\n",
      "Epoch 8\n",
      "Loss = 0.6421428874880504 | Training Accuracy = 0.5 | Val Loss = 0.6363124226956972 | Val Accuracy = 0.5\n",
      "Epoch 9\n",
      "Loss = 0.6363124226956972 | Training Accuracy = 0.5 | Val Loss = 0.6305093414563975 | Val Accuracy = 0.5\n",
      "Epoch 10\n",
      "Loss = 0.6305093414563975 | Training Accuracy = 0.5 | Val Loss = 0.6247368869501292 | Val Accuracy = 0.5\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1262.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 278.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1144.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 805.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 625.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 664.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 522.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1203.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1084.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1193.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 783.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1293.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 877.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 610.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 987.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1814.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1166.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1286.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1024.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1034.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 820.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1053.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 491.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 930.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 488.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1327.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 627.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1164.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1100.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1477.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1057.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1148.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1079.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1120.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1080.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 880.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.6247368869501292 | Training Accuracy = 0.5 | Val Loss = 0.6189859050725849 | Val Accuracy = 0.5\n",
      "Epoch 12\n",
      "Loss = 0.6189859050725849 | Training Accuracy = 0.5 | Val Loss = 0.613252277559553 | Val Accuracy = 0.5\n",
      "Epoch 13\n",
      "Loss = 0.613252277559553 | Training Accuracy = 0.5 | Val Loss = 0.6075325251219607 | Val Accuracy = 0.5\n",
      "Epoch 14\n",
      "Loss = 0.6075325251219607 | Training Accuracy = 0.5 | Val Loss = 0.6018235644664137 | Val Accuracy = 0.5\n",
      "Epoch 15\n",
      "Loss = 0.6018235644664137 | Training Accuracy = 0.5 | Val Loss = 0.5961226287093434 | Val Accuracy = 0.5\n",
      "Epoch 16\n",
      "Loss = 0.5961226287093434 | Training Accuracy = 0.5 | Val Loss = 0.5904272117688752 | Val Accuracy = 0.5\n",
      "Epoch 17\n",
      "Loss = 0.5904272117688752 | Training Accuracy = 0.5 | Val Loss = 0.5847350268351028 | Val Accuracy = 0.5\n",
      "Epoch 18\n",
      "Loss = 0.5847350268351028 | Training Accuracy = 0.5 | Val Loss = 0.5790439750660844 | Val Accuracy = 0.5\n",
      "Epoch 19\n",
      "Loss = 0.5790439750660844 | Training Accuracy = 0.5 | Val Loss = 0.5733521219099568 | Val Accuracy = 0.5\n",
      "Epoch 20\n",
      "Loss = 0.5733521219099568 | Training Accuracy = 0.5 | Val Loss = 0.5676576791807374 | Val Accuracy = 0.5\n",
      "Epoch 21\n",
      "Loss = 0.5676576791807374 | Training Accuracy = 0.5 | Val Loss = 0.5619589915202838 | Val Accuracy = 0.5\n",
      "Epoch 22\n",
      "Loss = 0.5619589915202838 | Training Accuracy = 0.5 | Val Loss = 0.5562545262414217 | Val Accuracy = 0.5\n",
      "Epoch 23\n",
      "Loss = 0.5562545262414217 | Training Accuracy = 0.5 | Val Loss = 0.5505428658100082 | Val Accuracy = 0.5\n",
      "Epoch 24\n",
      "Loss = 0.5505428658100082 | Training Accuracy = 0.5 | Val Loss = 0.5448227024148042 | Val Accuracy = 0.5\n",
      "Epoch 25\n",
      "Loss = 0.5448227024148042 | Training Accuracy = 0.75 | Val Loss = 0.539092834213239 | Val Accuracy = 0.75\n",
      "Epoch 26\n",
      "Loss = 0.539092834213239 | Training Accuracy = 0.75 | Val Loss = 0.5333521629426392 | Val Accuracy = 0.75\n",
      "Epoch 27\n",
      "Loss = 0.5333521629426392 | Training Accuracy = 1.0 | Val Loss = 0.5275996926603901 | Val Accuracy = 1.0\n",
      "Epoch 28\n",
      "Loss = 0.5275996926603901 | Training Accuracy = 1.0 | Val Loss = 0.521834529430182 | Val Accuracy = 1.0\n",
      "Epoch 29\n",
      "Loss = 0.521834529430182 | Training Accuracy = 1.0 | Val Loss = 0.5160691927969426 | Val Accuracy = 1.0\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1650.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1132.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1321.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1159.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 278.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1045.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1340.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1095.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 236.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 703.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 548.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1101.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 990.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 897.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1022.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1155.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1195.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1176.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 764.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 910.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1162.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 736.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 809.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 928.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 806.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1242.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 348.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1374.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 920.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1539.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 749.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1690.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1191.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1180.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 961.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 761.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 829.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 210.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1298.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 703.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1125.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.5160691927969426 | Training Accuracy = 1.0 | Val Loss = 0.5102896396035372 | Val Accuracy = 1.0\n",
      "Epoch 31\n",
      "Loss = 0.5102896396035372 | Training Accuracy = 1.0 | Val Loss = 0.5044720710883019 | Val Accuracy = 1.0\n",
      "Epoch 32\n",
      "Loss = 0.5044720710883019 | Training Accuracy = 1.0 | Val Loss = 0.49864795665436834 | Val Accuracy = 1.0\n",
      "Epoch 33\n",
      "Loss = 0.49864795665436834 | Training Accuracy = 1.0 | Val Loss = 0.49281624004077945 | Val Accuracy = 1.0\n",
      "Epoch 34\n",
      "Loss = 0.49281624004077945 | Training Accuracy = 1.0 | Val Loss = 0.48698587175706004 | Val Accuracy = 1.0\n",
      "Epoch 35\n",
      "Loss = 0.48698587175706004 | Training Accuracy = 1.0 | Val Loss = 0.48109608484157246 | Val Accuracy = 1.0\n",
      "Epoch 36\n",
      "Loss = 0.48109608484157246 | Training Accuracy = 1.0 | Val Loss = 0.47516936631001594 | Val Accuracy = 1.0\n",
      "Epoch 37\n",
      "Loss = 0.47516936631001594 | Training Accuracy = 1.0 | Val Loss = 0.4688816071813823 | Val Accuracy = 1.0\n",
      "Epoch 38\n",
      "Loss = 0.4688816071813823 | Training Accuracy = 1.0 | Val Loss = 0.4627394207998133 | Val Accuracy = 1.0\n",
      "Epoch 39\n",
      "Loss = 0.4627394207998133 | Training Accuracy = 1.0 | Val Loss = 0.4567357327185976 | Val Accuracy = 1.0\n",
      "Epoch 40\n",
      "Loss = 0.4567357327185976 | Training Accuracy = 1.0 | Val Loss = 0.44960183701036394 | Val Accuracy = 1.0\n",
      "Epoch 41\n",
      "Loss = 0.44960183701036394 | Training Accuracy = 1.0 | Val Loss = 0.4433824694974236 | Val Accuracy = 1.0\n",
      "Epoch 42\n",
      "Loss = 0.4433824694974236 | Training Accuracy = 1.0 | Val Loss = 0.4367759495610126 | Val Accuracy = 1.0\n",
      "Epoch 43\n",
      "Loss = 0.4367759495610126 | Training Accuracy = 1.0 | Val Loss = 0.430338574237771 | Val Accuracy = 1.0\n",
      "Epoch 44\n",
      "Loss = 0.430338574237771 | Training Accuracy = 1.0 | Val Loss = 0.42414808853083075 | Val Accuracy = 1.0\n",
      "Epoch 45\n",
      "Loss = 0.42414808853083075 | Training Accuracy = 1.0 | Val Loss = 0.4179505013646016 | Val Accuracy = 1.0\n",
      "Epoch 46\n",
      "Loss = 0.4179505013646016 | Training Accuracy = 1.0 | Val Loss = 0.41173904706747005 | Val Accuracy = 1.0\n",
      "Epoch 47\n",
      "Loss = 0.41173904706747005 | Training Accuracy = 1.0 | Val Loss = 0.40551752417921083 | Val Accuracy = 1.0\n",
      "Epoch 48\n",
      "Loss = 0.40551752417921083 | Training Accuracy = 1.0 | Val Loss = 0.3992898924109998 | Val Accuracy = 1.0\n",
      "Epoch 49\n",
      "Loss = 0.3992898924109998 | Training Accuracy = 1.0 | Val Loss = 0.39309133538585744 | Val Accuracy = 1.0\n",
      "Epoch 50\n",
      "Loss = 0.39309133538585744 | Training Accuracy = 1.0 | Val Loss = 0.38697677506178607 | Val Accuracy = 1.0\n",
      "Epoch 51\n",
      "Loss = 0.38697677506178607 | Training Accuracy = 1.0 | Val Loss = 0.3810174561243225 | Val Accuracy = 1.0\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1576.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1054.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1119.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1405.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 432.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 930.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1181.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1300.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1062.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1299.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 991.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 269.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 868.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1017.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1177.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 337.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1004.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 557.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1238.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1006.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1193.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 568.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1164.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1011.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1221.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1079.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 777.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 922.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1805.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 326.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 858.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1240.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 818.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1097.99it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.3810174561243225 | Training Accuracy = 1.0 | Val Loss = 0.3747515588874246 | Val Accuracy = 1.0\n",
      "Epoch 53\n",
      "Loss = 0.3747515588874246 | Training Accuracy = 1.0 | Val Loss = 0.36844857777445944 | Val Accuracy = 1.0\n",
      "Epoch 54\n",
      "Loss = 0.36844857777445944 | Training Accuracy = 1.0 | Val Loss = 0.362234776132652 | Val Accuracy = 1.0\n",
      "Epoch 55\n",
      "Loss = 0.362234776132652 | Training Accuracy = 1.0 | Val Loss = 0.3560416585677346 | Val Accuracy = 1.0\n",
      "Epoch 56\n",
      "Loss = 0.3560416585677346 | Training Accuracy = 1.0 | Val Loss = 0.34986592906218955 | Val Accuracy = 1.0\n",
      "Epoch 57\n",
      "Loss = 0.34986592906218955 | Training Accuracy = 1.0 | Val Loss = 0.3437106862803615 | Val Accuracy = 1.0\n",
      "Epoch 58\n",
      "Loss = 0.3437106862803615 | Training Accuracy = 1.0 | Val Loss = 0.3376353586502209 | Val Accuracy = 1.0\n",
      "Epoch 59\n",
      "Loss = 0.3376353586502209 | Training Accuracy = 1.0 | Val Loss = 0.33176696934203975 | Val Accuracy = 1.0\n",
      "Epoch 60\n",
      "Loss = 0.33176696934203975 | Training Accuracy = 1.0 | Val Loss = 0.32576988188480566 | Val Accuracy = 1.0\n",
      "Epoch 61\n",
      "Loss = 0.32576988188480566 | Training Accuracy = 1.0 | Val Loss = 0.3198302083360926 | Val Accuracy = 1.0\n",
      "Epoch 62\n",
      "Loss = 0.3198302083360926 | Training Accuracy = 1.0 | Val Loss = 0.3138587822007371 | Val Accuracy = 1.0\n",
      "Epoch 63\n",
      "Loss = 0.3138587822007371 | Training Accuracy = 1.0 | Val Loss = 0.30807009870583874 | Val Accuracy = 1.0\n",
      "Epoch 64\n",
      "Loss = 0.30807009870583874 | Training Accuracy = 1.0 | Val Loss = 0.30204863727282855 | Val Accuracy = 1.0\n",
      "Epoch 65\n",
      "Loss = 0.30204863727282855 | Training Accuracy = 1.0 | Val Loss = 0.2961498667654637 | Val Accuracy = 1.0\n",
      "Epoch 66\n",
      "Loss = 0.2961498667654637 | Training Accuracy = 1.0 | Val Loss = 0.2903683628322381 | Val Accuracy = 1.0\n",
      "Epoch 67\n",
      "Loss = 0.2903683628322381 | Training Accuracy = 1.0 | Val Loss = 0.2846263077754886 | Val Accuracy = 1.0\n",
      "Epoch 68\n",
      "Loss = 0.2846263077754886 | Training Accuracy = 1.0 | Val Loss = 0.2790391972950644 | Val Accuracy = 1.0\n",
      "Epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 309.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 524.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1203.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 954.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1289.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 855.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1200.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 819.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 227.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 880.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 697.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1226.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1037.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1141.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 757.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1072.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1062.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 814.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 398.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 830.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 813.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1234.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 460.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1198.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 937.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1261.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 785.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 909.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 686.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 631.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1482.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1493.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1027.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 953.68it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2790391972950644 | Training Accuracy = 1.0 | Val Loss = 0.2734500001409982 | Val Accuracy = 1.0\n",
      "Epoch 70\n",
      "Loss = 0.2734500001409982 | Training Accuracy = 1.0 | Val Loss = 0.2681225153107171 | Val Accuracy = 1.0\n",
      "Epoch 71\n",
      "Loss = 0.2681225153107171 | Training Accuracy = 1.0 | Val Loss = 0.2627886885280921 | Val Accuracy = 1.0\n",
      "Epoch 72\n",
      "Loss = 0.2627886885280921 | Training Accuracy = 1.0 | Val Loss = 0.2573719753546556 | Val Accuracy = 1.0\n",
      "Epoch 73\n",
      "Loss = 0.2573719753546556 | Training Accuracy = 1.0 | Val Loss = 0.2522569218702651 | Val Accuracy = 1.0\n",
      "Epoch 74\n",
      "Loss = 0.2522569218702651 | Training Accuracy = 1.0 | Val Loss = 0.2468736910423922 | Val Accuracy = 1.0\n",
      "Epoch 75\n",
      "Loss = 0.2468736910423922 | Training Accuracy = 1.0 | Val Loss = 0.24184070941642344 | Val Accuracy = 1.0\n",
      "Epoch 76\n",
      "Loss = 0.24184070941642344 | Training Accuracy = 1.0 | Val Loss = 0.23669172466122884 | Val Accuracy = 1.0\n",
      "Epoch 77\n",
      "Loss = 0.23669172466122884 | Training Accuracy = 1.0 | Val Loss = 0.23177482291420184 | Val Accuracy = 1.0\n",
      "Epoch 78\n",
      "Loss = 0.23177482291420184 | Training Accuracy = 1.0 | Val Loss = 0.22683584182488345 | Val Accuracy = 1.0\n",
      "Epoch 79\n",
      "Loss = 0.22683584182488345 | Training Accuracy = 1.0 | Val Loss = 0.22228766172590106 | Val Accuracy = 1.0\n",
      "Epoch 80\n",
      "Loss = 0.22228766172590106 | Training Accuracy = 1.0 | Val Loss = 0.21787591571892298 | Val Accuracy = 1.0\n",
      "Epoch 81\n",
      "Loss = 0.21787591571892298 | Training Accuracy = 1.0 | Val Loss = 0.21385430065046118 | Val Accuracy = 1.0\n",
      "Epoch 82\n",
      "Loss = 0.21385430065046118 | Training Accuracy = 1.0 | Val Loss = 0.20920148822506868 | Val Accuracy = 1.0\n",
      "Epoch 83\n",
      "Loss = 0.20920148822506868 | Training Accuracy = 1.0 | Val Loss = 0.20529657702766485 | Val Accuracy = 1.0\n",
      "Epoch 84\n",
      "Loss = 0.20529657702766485 | Training Accuracy = 1.0 | Val Loss = 0.20077593050828552 | Val Accuracy = 1.0\n",
      "Epoch 85\n",
      "Loss = 0.20077593050828552 | Training Accuracy = 1.0 | Val Loss = 0.19732668442271176 | Val Accuracy = 1.0\n",
      "Epoch 86\n",
      "Loss = 0.19732668442271176 | Training Accuracy = 1.0 | Val Loss = 0.1928221678808272 | Val Accuracy = 1.0\n",
      "Epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 607.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1537.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 897.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 839.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 690.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1137.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 729.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 217.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1244.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 774.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1263.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 888.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1213.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1085.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 311.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1168.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1117.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 348.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 640.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1223.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 596.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1146.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 315.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1134.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 825.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1029.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1102.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1248.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.1928221678808272 | Training Accuracy = 1.0 | Val Loss = 0.19123299707082542 | Val Accuracy = 1.0\n",
      "Epoch 88\n",
      "Loss = 0.19123299707082542 | Training Accuracy = 1.0 | Val Loss = 0.1866878268951916 | Val Accuracy = 1.0\n",
      "Epoch 89\n",
      "Loss = 0.1866878268951916 | Training Accuracy = 1.0 | Val Loss = 0.18603958041881366 | Val Accuracy = 1.0\n",
      "Epoch 90\n",
      "Loss = 0.18603958041881366 | Training Accuracy = 1.0 | Val Loss = 0.18070855698052302 | Val Accuracy = 1.0\n",
      "Epoch 91\n",
      "Loss = 0.18070855698052302 | Training Accuracy = 1.0 | Val Loss = 0.18284538611950904 | Val Accuracy = 1.0\n",
      "Epoch 92\n",
      "Loss = 0.18284538611950904 | Training Accuracy = 1.0 | Val Loss = 0.17609678295713777 | Val Accuracy = 1.0\n",
      "Epoch 93\n",
      "Loss = 0.17609678295713777 | Training Accuracy = 1.0 | Val Loss = 0.181091805237042 | Val Accuracy = 1.0\n",
      "Epoch 94\n",
      "Loss = 0.181091805237042 | Training Accuracy = 1.0 | Val Loss = 0.1707060454863957 | Val Accuracy = 1.0\n",
      "Epoch 95\n",
      "Loss = 0.1707060454863957 | Training Accuracy = 1.0 | Val Loss = 0.17542713443487412 | Val Accuracy = 1.0\n",
      "Epoch 96\n",
      "Loss = 0.17542713443487412 | Training Accuracy = 1.0 | Val Loss = 0.16418179177167153 | Val Accuracy = 1.0\n",
      "Epoch 97\n",
      "Loss = 0.16418179177167153 | Training Accuracy = 1.0 | Val Loss = 0.16366937559924186 | Val Accuracy = 1.0\n",
      "Epoch 98\n",
      "Loss = 0.16366937559924186 | Training Accuracy = 1.0 | Val Loss = 0.15529547435534186 | Val Accuracy = 1.0\n",
      "Epoch 99\n",
      "Loss = 0.15529547435534186 | Training Accuracy = 1.0 | Val Loss = 0.15404206683881302 | Val Accuracy = 1.0\n",
      "Epoch 100\n",
      "Loss = 0.15404206683881302 | Training Accuracy = 1.0 | Val Loss = 0.14782625847598396 | Val Accuracy = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get preprocessed training and validation data\n",
    "\n",
    "X_train = np.array([\n",
    "    [1, 2, 1, 2],\n",
    "    [2, 4, 2, 4],\n",
    "    [2, 1, 2, 1],\n",
    "    [4, 2, 4, 2],\n",
    "])\n",
    "\n",
    "y_train = np.array([0, 1, 0, 1])\n",
    "X_val = X_train.copy()\n",
    "y_val = y_train.copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "# add some layers\n",
    "model.add_layer(Linear(X_train.shape[1], 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 2))\n",
    "\n",
    "model = train(model, X_train , y_train, minibatch_size=4, epoch=100,\n",
    "           learning_rate=0.1, X_val=X_val, y_val=y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data\n",
    "\n",
    "def vis(img, label):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "vis_idx = 1\n",
    "vis(X_val[vis_idx].reshape(-1, 28), y_val[vis_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 784)\n",
      "(17500, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 19/411 [00:00<00:02, 187.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 124.18it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 300.21it/s]\n",
      "  3%|▎         | 12/411 [00:00<00:03, 115.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.1998314458187358 | Training Accuracy = 0.8976 | Val Loss = 0.18645351786898343 | Val Accuracy = 0.8888\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 110.48it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 344.53it/s]\n",
      "  4%|▎         | 15/411 [00:00<00:02, 148.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.366326231954017 | Training Accuracy = 0.9352761904761905 | Val Loss = 0.11366650330198699 | Val Accuracy = 0.9238285714285714\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 128.25it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 373.57it/s]\n",
      "  4%|▍         | 16/411 [00:00<00:02, 150.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.3106675162406056 | Training Accuracy = 0.9449142857142857 | Val Loss = 0.10049779437928447 | Val Accuracy = 0.9316571428571429\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:02<00:00, 138.94it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 274.11it/s]\n",
      "  3%|▎         | 12/411 [00:00<00:03, 119.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2817044622839786 | Training Accuracy = 0.9472 | Val Loss = 0.10024133917260326 | Val Accuracy = 0.9339428571428572\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 132.42it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 343.68it/s]\n",
      "  4%|▍         | 16/411 [00:00<00:02, 155.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2606372657095778 | Training Accuracy = 0.9505142857142858 | Val Loss = 0.09820740052184003 | Val Accuracy = 0.9364\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:02<00:00, 150.90it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 329.98it/s]\n",
      "  3%|▎         | 14/411 [00:00<00:02, 136.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2451825155835454 | Training Accuracy = 0.9526476190476191 | Val Loss = 0.09841648591580933 | Val Accuracy = 0.9373142857142858\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:02<00:00, 143.35it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 274.58it/s]\n",
      "  3%|▎         | 11/411 [00:00<00:03, 101.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.23398151014339966 | Training Accuracy = 0.9544190476190476 | Val Loss = 0.1004596801753301 | Val Accuracy = 0.9374857142857143\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 127.75it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 272.29it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:05, 78.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.22485948845046141 | Training Accuracy = 0.9566095238095238 | Val Loss = 0.09887217416058118 | Val Accuracy = 0.9405714285714286\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 116.88it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 289.28it/s]\n",
      "  1%|▏         | 6/411 [00:00<00:07, 55.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2169012439418813 | Training Accuracy = 0.9589333333333333 | Val Loss = 0.09520575661378539 | Val Accuracy = 0.9420571428571428\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:03<00:00, 120.45it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 324.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2106751938478122 | Training Accuracy = 0.9588571428571429 | Val Loss = 0.09428998855873569 | Val Accuracy = 0.9426285714285715\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "# add some layers\n",
    "model.add_layer(Linear(X.shape[1], 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 10))\n",
    "\n",
    "\n",
    "model = train(model, X_train , y_train, minibatch_size=128, epoch=10,\n",
    "           learning_rate=0.001, X_val=X_val, y_val=y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize prediction \n",
    "\n",
    "vis_idx = 1000\n",
    "\n",
    "pred = model.predict(X_val[vis_idx])\n",
    "vis(X_val[vis_idx].reshape(-1, 28), pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1) Add computational graph instead of list, model saving/loading, more optimizers, shedulers, loss functions, operations, gpu support, utility tools ...\n",
    "\n",
    "... Or simply use Pytorch/TF/whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
